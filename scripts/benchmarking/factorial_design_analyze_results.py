"""
This script analyzes the results (runtime) of a factorial design run in divbase (run using factorial_design_submit_jobs.py).
Instead of polling for task completion, this script is intended to be run after the tasks have completed. The input is a JSON file with task records that was generated by the previous script.

This script takes the task IDs from the json file and fetches their runtime information from the Flower API. The factors (samples, variants) and response (runtime) are then visualised and an
ANOVA table is calculated.

NOTE! The factorial design scripts require dependencies that have been put in the optional-dependencies part of pyproject.toml since they can take long to install.
Run 'uv pip install .[benchmarking]' OR 'pip install .[benchmarking]' first, as described in the usage info below:

Usage:
    uv pip install .[benchmarking]
    python scripts/benchmarking/factorial_design_analyze_results.py
"""

import argparse
import json
import re
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import requests
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as ols
from _benchmarking_shared_utils import FLOWER_PASSWORD, FLOWER_USER
from matplotlib.lines import Line2D
from matplotlib.patches import Patch
from scipy.interpolate import griddata


def parse_arguments():
    parser = argparse.ArgumentParser(
        description="Analyse the results (runtime) of a factorial design run in divbase (run using factorial_design_submit_jobs.py)."
    )
    parser.add_argument(
        "--input-json",
        type=str,
        default=Path("task_records.json"),
        required=False,
        help="Path to the JSON file with task records. If the task record already contains runtime results, it skips checking the flower logs and goes directly to the data analysis.",
    )
    parser.add_argument(
        "--output-json",
        type=str,
        default=Path("task_records_with_runtime.json"),
        required=False,
        help="Path to the output JSON file with runtime information.",
    )

    return parser.parse_args()


def fetch_flower_tasks():
    FLOWER_API = "http://localhost:5555/api/tasks"

    auth = (FLOWER_USER, FLOWER_PASSWORD)
    response = requests.get(FLOWER_API, auth=auth, timeout=3)
    response.raise_for_status()
    return response.json()


def get_runtime_of_succeeded_tasks(task_records: list[dict], output_path: Path) -> list[dict]:
    """
    Use the Flower API to get the runtime of the task IDs in the input JSON file.
    Only obtains the runtimes of the tasks that completed successfully.
    Adds the results to the input file and writes it to disk."""
    # TODO write somewhere that this assumes that all tasks have finished and that they have been sucessful. maybe print a message about which records in the json that are missing runtims in the flower logs
    flower_log = fetch_flower_tasks()

    for record in task_records:
        task_id = record["task_id"]
        task_info = flower_log.get(task_id)
        if task_info:
            runtime = task_info.get("runtime")
            started = task_info.get("started")
            succeeded = task_info.get("succeeded")
            if started and succeeded:
                elapsed_time = succeeded - started
            else:
                elapsed_time = None
            record["runtime"] = runtime
            record["elapsed_time"] = elapsed_time
        else:
            print(f"Task {task_id}: not found in Flower log")
            record["runtime"] = None

    with open(output_path, "w") as f:
        json.dump(task_records, f, indent=2)

    return task_records  # strictly not needed since list and dicts are mutable, but is useful for clarity


def plot_3D_response_surface(df: pd.DataFrame, query_str: str) -> None:
    """Plot the 3D response surface of the factorial design using mean runtime and show std as error bars."""

    grouped = df.groupby(["number_of_samples", "number_of_variants"], as_index=False).agg(
        runtime_mean=("runtime", "mean"),
        runtime_std=("runtime", "std"),
        n_replicates=("runtime", "count"),
    )

    n_replicates_set = set(grouped["n_replicates"])
    if len(n_replicates_set) == 1:
        n_replicates_str = f"{list(n_replicates_set)[0]}"
    else:
        n_replicates_str = f"varies ({min(n_replicates_set)}â€“{max(n_replicates_set)})"

    xi = np.linspace(grouped["number_of_samples"].min(), grouped["number_of_samples"].max(), 50)
    yi = np.linspace(grouped["number_of_variants"].min(), grouped["number_of_variants"].max(), 50)
    xi, yi = np.meshgrid(xi, yi)
    zi = griddata(
        (grouped["number_of_samples"], grouped["number_of_variants"]), grouped["runtime_mean"], (xi, yi), method="cubic"
    )

    fig = plt.figure()
    ax = fig.add_subplot(111, projection="3d")

    ax.plot_surface(xi, yi, zi, cmap="viridis", alpha=0.8)

    ax.scatter(
        grouped["number_of_samples"],
        grouped["number_of_variants"],
        grouped["runtime_mean"],
        color="r",
        label=f"Mean runtime (n_replicates={n_replicates_str})",
    )
    ax.set_title("3D Response Surface")
    if query_str:
        ax.set_title(f"3D Response Surface\n{query_str}", fontsize=10)

    # Plot error bars (std) in z-direction
    for _, row in grouped.iterrows():
        if not np.isnan(row["runtime_std"]):
            ax.plot(
                [row["number_of_samples"], row["number_of_samples"]],
                [row["number_of_variants"], row["number_of_variants"]],
                [row["runtime_mean"] - row["runtime_std"], row["runtime_mean"] + row["runtime_std"]],
                color="k",
            )

    ax.set_xlabel("Samples")
    ax.set_ylabel("Variants")
    ax.set_zlabel("Mean Runtime (s)")
    ax.legend()

    # TODO add legend that describes the query and the heatmap


def plot_main_effects(df: pd.DataFrame, query_str: str):
    """Plot the main effects of each factor on runtime."""
    plt.figure()
    legend_elements = [
        Line2D([0], [0], color="b", marker="o", label="Mean runtime"),
        Patch(facecolor="b", alpha=0.2, label="Std. dev."),
    ]
    ax1 = plt.gca()
    sns.lineplot(x="number_of_samples", y="runtime", data=df, marker="o", errorbar="sd", ax=ax1)
    ax1.set_title(f"Main Effect: Number of Samples\n{query_str}", fontsize=10)
    ax1.set_xlabel("Number of Samples")
    ax1.set_ylabel("Mean Runtime (s)")

    ax1.legend(handles=legend_elements, loc="best")

    plt.figure()
    ax2 = plt.gca()
    sns.lineplot(x="number_of_variants", y="runtime", data=df, marker="o", errorbar="sd", ax=ax2)
    ax2.set_title(f"Main Effect: Number of Variants\n{query_str}", fontsize=10)
    ax2.set_xlabel("Number of Variants")
    ax2.set_ylabel("Mean Runtime (s)")
    ax2.legend(handles=legend_elements, loc="best")


def plot_interaction_effects(df: pd.DataFrame, query_str: str):
    """Classic interaction plot: one line per binned level of number_of_variants."""

    df = df.copy()
    df["samples_bin"] = pd.qcut(df["number_of_samples"], q=2, labels=[-1, 1])
    df["variants_bin"] = pd.qcut(df["number_of_variants"], q=2, labels=[-1, 1])

    plt.figure()
    ax = plt.gca()

    sns.lineplot(x="samples_bin", y="runtime", hue="variants_bin", data=df, marker="o", errorbar="sd")
    ax.set_title(f"Interaction Effect: Samples x Variants\n{query_str}", fontsize=10)
    ax.set_xlabel("Number of Samples (coded -1, 1)")
    ax.set_ylabel("Mean Runtime (s)")

    legend_elements = [
        Patch(facecolor="b", alpha=0.2, label="Std. dev. (shaded area)"),
    ]
    handles, _ = ax.get_legend_handles_labels()
    ax.legend(handles=handles + legend_elements, loc="best", title="Variants Bin (coded -1, 1)")


def z_score_normalization(df: pd.DataFrame) -> pd.DataFrame:
    """
    If the scales of the factors differ dramatically, it can affect regression and ANOVA analysis.
    For example: the number of samples range between 10-1000 and the number of variants between
    10-10000000. Z-score normalization can be used to adress this. The method transforms the dataset
    using the mean and standard deviation for each data point.

    See e.g.
    https://www.geeksforgeeks.org/data-analysis/z-score-normalization-definition-and-examples/
    """
    df = df.copy()
    df["number_of_samples"] = (df["number_of_samples"] - df["number_of_samples"].mean()) / df["number_of_samples"].std()
    df["number_of_variants"] = (df["number_of_variants"] - df["number_of_variants"].mean()) / df[
        "number_of_variants"
    ].std()
    return df


def run_anova(df: pd.DataFrame):
    """Fit a linear model with main effects and interaction and then calculate an ANOVA table."""
    model = ols.ols(
        "runtime ~ number_of_samples + number_of_variants + number_of_samples:number_of_variants", data=df
    ).fit()
    print(model.summary())

    anova_table = sm.stats.anova_lm(model, typ=2)
    print("\nANOVA Table:")
    print(anova_table)


def format_query_for_plot_title(df: pd.DataFrame) -> str:
    """
    Get the query string from the dataframe. Drop the --metadata-tsv-name and --project arguments
    so that the it can better fit as a plot title. Insert newlines before --command,
    and remove empty spaces after newlines.
    """

    query_str = df["cmd_query"].iloc[0] if "cmd_query" in df.columns else ""

    query_str = re.sub(r"--metadata-tsv-name\s+\S+", "", query_str)
    query_str = re.sub(r"--project\s+\S+", "", query_str)
    query_str = re.sub(r"\s+", " ", query_str).strip()

    query_str = re.sub(r"(--command)", r"\n\1", query_str)
    query_str = re.sub(r"[ ]{2,}", " ", query_str)
    query_str = re.sub(r"\n\s*", "\n", query_str).strip()

    return query_str


def main():
    args = parse_arguments()
    task_records_path = Path(args.input_json)
    output_path = Path(args.output_json)

    with open(task_records_path) as f:
        task_records = json.load(f)

    all_records_have_runtime = all(
        (
            "runtime" in record
            and record["runtime"] is not None
            and "elapsed_time" in record
            and record["elapsed_time"] is not None
        )
        for record in task_records
    )

    if all_records_have_runtime:
        updated_task_records = task_records
        print("All records already have runtime and elapsed_time. Skipping Flower fetch and file write.")
    else:
        updated_task_records = get_runtime_of_succeeded_tasks(task_records, output_path)
    df = pd.DataFrame(updated_task_records)
    df = df[df["runtime"].notnull()]

    query_str = format_query_for_plot_title(df)

    plot_3D_response_surface(df, query_str)

    plot_main_effects(df, query_str)

    plot_interaction_effects(df, query_str)

    df_z_score_normalized = z_score_normalization(df)

    run_anova(df_z_score_normalized)

    plt.show()


if __name__ == "__main__":
    main()
