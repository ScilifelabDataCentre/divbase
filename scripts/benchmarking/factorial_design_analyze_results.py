"""
This script analyzes the results (runtime) of a factorial design run in divbase (run using factorial_design_submit_jobs.py).
Instead of polling for task completion, this script is intended to be run after the tasks have completed. The input is a JSON file with task records that was generated by the previous script.

This script takes the task IDs from the json file and fetches their runtime information from the Flower API. The factors (samples, variants) and response (runtime) are then visualised and an
ANOVA table is calculated.

Usage:
    python scripts/benchmarking/factorial_design_analyze_results.py
"""

import argparse
import json
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import requests
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as ols
from _benchmarking_shared_utils import FLOWER_PASSWORD, FLOWER_USER
from scipy.interpolate import griddata


def parse_arguments():
    parser = argparse.ArgumentParser(
        description="Analyse the results (runtime) of a factorial design run in divbase (run using factorial_design_submit_jobs.py)."
    )
    parser.add_argument(
        "--input-json",
        type=str,
        default=Path("task_records.json"),
        required=False,
        help="Path to the JSON file with task records.",
    )
    parser.add_argument(
        "--output-json",
        type=str,
        default=Path("task_records_with_runtime.json"),
        required=False,
        help="Path to the output JSON file with runtime information.",
    )
    return parser.parse_args()


def fetch_flower_tasks():
    FLOWER_API = "http://localhost:5555/api/tasks"

    auth = (FLOWER_USER, FLOWER_PASSWORD)
    response = requests.get(FLOWER_API, auth=auth, timeout=3)
    response.raise_for_status()
    return response.json()


def get_runtime_of_succeeded_tasks(task_records: list[dict], output_path: Path) -> list[dict]:
    """Use the Flower API to get the runtime of the task IDs in the input JSON file. Only obtains the runtimes of the tasks that completed successfully."""
    # TODO write somewhere that this assumes that all tasks have finished and that they have been sucessful. maybe print a message about which records in the json that are missing runtims in the flower logs
    flower_log = fetch_flower_tasks()

    for record in task_records:
        task_id = record["task_id"]
        task_info = flower_log.get(task_id)
        if task_info:
            runtime = task_info.get("runtime")
            started = task_info.get("started")
            succeeded = task_info.get("succeeded")
            if started and succeeded:
                elapsed_time = succeeded - started
            else:
                elapsed_time = None
            record["runtime"] = runtime
            record["elapsed_time"] = elapsed_time
        else:
            print(f"Task {task_id}: not found in Flower log")
            record["runtime"] = None

    with open(output_path, "w") as f:
        json.dump(task_records, f, indent=2)

    return task_records  # strictly not needed since list and dicts are mutable, but is useful for clarity


def plot_3D_response_surface(df: pd.DataFrame) -> None:
    """Plot the 3D response surface of the factorial design using mean runtime and show std as error bars."""

    grouped = df.groupby(["number_of_samples", "number_of_variants"], as_index=False).agg(
        runtime_mean=("runtime", "mean"),
        runtime_std=("runtime", "std"),
        n_replicates=("runtime", "count"),
    )

    n_replicates_set = set(grouped["n_replicates"])
    if len(n_replicates_set) == 1:
        n_replicates_str = f"{list(n_replicates_set)[0]}"
    else:
        n_replicates_str = f"varies ({min(n_replicates_set)}â€“{max(n_replicates_set)})"

    xi = np.linspace(grouped["number_of_samples"].min(), grouped["number_of_samples"].max(), 50)
    yi = np.linspace(grouped["number_of_variants"].min(), grouped["number_of_variants"].max(), 50)
    xi, yi = np.meshgrid(xi, yi)
    zi = griddata(
        (grouped["number_of_samples"], grouped["number_of_variants"]), grouped["runtime_mean"], (xi, yi), method="cubic"
    )

    fig = plt.figure()
    ax = fig.add_subplot(111, projection="3d")

    ax.plot_surface(xi, yi, zi, cmap="viridis", alpha=0.8)

    ax.scatter(
        grouped["number_of_samples"],
        grouped["number_of_variants"],
        grouped["runtime_mean"],
        color="r",
        label=f"Mean runtime (n_replicates={n_replicates_str})",
    )

    # Plot error bars (std) in z-direction
    for _, row in grouped.iterrows():
        if not np.isnan(row["runtime_std"]):
            ax.plot(
                [row["number_of_samples"], row["number_of_samples"]],
                [row["number_of_variants"], row["number_of_variants"]],
                [row["runtime_mean"] - row["runtime_std"], row["runtime_mean"] + row["runtime_std"]],
                color="k",
            )

    ax.set_xlabel("Samples")
    ax.set_ylabel("Variants")
    ax.set_zlabel("Mean Runtime (s)")
    ax.legend()

    # TODO add legend that describes the query and the heatmap


def plot_main_effects(df: pd.DataFrame):
    """Plot the main effects of each factor on runtime."""
    plt.figure()
    sns.lineplot(x="number_of_samples", y="runtime", data=df, marker="o")
    plt.title("Main Effect: Number of Samples")
    plt.xlabel("Number of Samples")
    plt.ylabel("Mean Runtime (s)")

    plt.figure()
    sns.lineplot(x="number_of_variants", y="runtime", data=df, marker="o")
    plt.title("Main Effect: Number of Variants")
    plt.xlabel("Number of Variants")
    plt.ylabel("Mean Runtime (s)")

    # TODO add legend that describes the query and the standard deviation


def plot_interaction_effects(df: pd.DataFrame):
    """Classic interaction plot: one line per binned level of number_of_variants."""

    df = df.copy()
    df["variants_bin"] = pd.qcut(df["number_of_variants"], q=3, duplicates="drop")  # q= number of bins

    plt.figure()
    sns.lineplot(x="number_of_samples", y="runtime", hue="variants_bin", data=df, marker="o")
    plt.title("Interaction Effect: Samples x Variants")
    plt.xlabel("Number of Samples")
    plt.ylabel("Mean Runtime (s)")
    plt.legend(title="Variants Bin")


def run_anova(df: pd.DataFrame):
    """Fit a linear model with main effects and interaction and then calculate an ANOVA table."""
    model = ols.ols(
        "runtime ~ number_of_samples + number_of_variants + number_of_samples:number_of_variants", data=df
    ).fit()
    print(model.summary())

    anova_table = sm.stats.anova_lm(model, typ=2)
    print("\nANOVA Table:")
    print(anova_table)


def main():
    args = parse_arguments()
    task_records_path = Path(args.input_json)
    output_path = Path(args.output_json)

    with open(task_records_path) as f:
        task_records = json.load(f)

    updated_task_records = get_runtime_of_succeeded_tasks(task_records, output_path)

    df = pd.DataFrame(updated_task_records)
    df = df[df["runtime"].notnull()]

    run_anova(df)

    plot_3D_response_surface(df)

    plot_main_effects(df)

    plot_interaction_effects(df)

    plt.show()


if __name__ == "__main__":
    main()
