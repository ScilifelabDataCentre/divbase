"""
Tests for the "divbase-cli files" commands

All tests are run against the docker compose test overlay

A clean project (its bucket is auto emptied before each test) is available to any test that requires a clean slate.
"""

import csv
import os
from io import StringIO

import boto3
import pytest
from typer.testing import CliRunner

from divbase_cli.cli_commands.file_cli import NO_FILES_SPECIFIED_MSG
from divbase_cli.cli_exceptions import DivBaseAPIError, FilesAlreadyInProjectError, UnsupportedFileTypeError
from divbase_cli.divbase_cli import app
from divbase_lib.divbase_constants import (
    MAX_S3_API_BATCH_SIZE,
    QUERY_RESULTS_FILE_PREFIX,
    S3_MULTIPART_UPLOAD_THRESHOLD,
)
from divbase_lib.s3_checksums import calculate_composite_md5_s3_etag

runner = CliRunner()


@pytest.fixture(autouse=True)
def start_with_clean_project(CONSTANTS):
    """
    For tests that require a project with a clean bucket, this fixture will
    ensure that the CONSTANTS["CLEANED_PROJECT"]'s bucket is empty before running the test.

    Caution:
    If you modify the approach make sure your implementation does not just add delete markers.
    The files need to be actually deleted.
    """
    s3_resource = boto3.resource(
        "s3",
        endpoint_url=CONSTANTS["MINIO_URL"],
        aws_access_key_id=CONSTANTS["BAD_ACCESS_KEY"],
        aws_secret_access_key=CONSTANTS["BAD_SECRET_KEY"],
    )

    # pylance does not understand boto3 resource returns types, hence ignore below
    cleaned_project_bucket_name = CONSTANTS["PROJECT_TO_BUCKET_MAP"][CONSTANTS["CLEANED_PROJECT"]]

    bucket = s3_resource.Bucket(cleaned_project_bucket_name)  # type: ignore
    bucket.object_versions.delete()

    yield


@pytest.fixture(scope="module")
def large_file_for_multipart(tmp_path_factory):
    """
    Fixture that creates a large file just above the multipart upload threshold
    with random data to test multipart upload and downloads

    Returns path to the file.
    """
    one_mib = 1024 * 1024
    large_file_path = tmp_path_factory.mktemp("large_files") / "large_random_file.vcf.gz"
    file_size = S3_MULTIPART_UPLOAD_THRESHOLD + one_mib

    with open(large_file_path, "wb") as f:
        for _ in range(file_size // one_mib):
            f.write(os.urandom(one_mib))
    return large_file_path


def calculate_numb_table_rows_printed(stdout: str) -> int:
    """
    Helper to count the number of table rows printed in the stdout of a command.
    You can use this to validate how many data rows were printed in a table generated by Rich.
    """
    table_size = [line for line in stdout.splitlines() if line.strip().startswith(("│", "┃"))]
    return len(table_size) - 1  # Subtract 1 for the header


@pytest.mark.parametrize(
    "command",
    [
        "upload",
        "download",
        "rm",
        "restore",
    ],
)
def test_files_commands_fail_without_files(logged_in_edit_user_with_existing_config, CONSTANTS, command):
    """Test that different files subcommands that require file inputs fail when none are provided."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    full_command = f"files {command} --project {clean_project}"

    result = runner.invoke(app, full_command)
    assert result.exit_code == 1
    assert NO_FILES_SPECIFIED_MSG in result.stdout


def test_list_files(logged_in_edit_user_with_existing_config, CONSTANTS):
    """Test basic usage of files ls command."""
    command = "files ls"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    default_project = CONSTANTS["DEFAULT_PROJECT"]

    for file in CONSTANTS["PROJECT_CONTENTS"][default_project]:
        assert file in result.stdout

    column_names = ["Name", "File size", "Upload date (CET)", "MD5 checksum"]
    assert all(header in result.stdout for header in column_names)


def test_list_non_default_project(logged_in_edit_user_with_existing_config, CONSTANTS):
    """Test list files for the non-default project."""
    non_default_project = CONSTANTS["NON_DEFAULT_PROJECT"]
    files_in_project = CONSTANTS["PROJECT_CONTENTS"][non_default_project]

    command = f"files ls --project {non_default_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    for file in files_in_project:
        assert file in result.stdout


def test_list_files_empty_project(logged_in_edit_user_with_existing_config, CONSTANTS):
    """Test list files for an empty project."""
    command = f"files ls --project {CONSTANTS['EMPTY_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert "No files found" in result.stdout


@pytest.mark.skipif("not config.getoption('--run-slow')", reason="Only run when --run-slow is given")
def test_list_files_handles_pagination(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """
    Tests that the list files command can paginate correctly by going through all results when a project
    contains more than s3 limit for a single API call.
    """
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    upload_dir = tmp_path / "many_files_dir"
    upload_dir.mkdir()
    # S3 hard limits at 1000, so guarantee pagination by going over that
    num_files = 1005

    file_names = {f"test_file_{i}.tsv" for i in range(num_files)}
    for name in file_names:
        (upload_dir / name).write_text(f"content_{name}")

    upload_command = f"files upload --upload-dir {upload_dir} --project {clean_project}"
    upload_result = runner.invoke(app, upload_command)
    assert upload_result.exit_code == 0

    list_command = f"files ls --project {clean_project}"
    list_result = runner.invoke(app, list_command)
    assert list_result.exit_code == 0

    for name in file_names:
        assert name in list_result.stdout
    assert calculate_numb_table_rows_printed(list_result.stdout) == num_files


def test_list_files_with_prefix_filter(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test that the --prefix flag correctly filters the file list."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    (tmp_path / "prefix_a_1.tsv").write_text("a1")
    (tmp_path / "prefix_a_2.tsv").write_text("a2")
    (tmp_path / "prefix_b_1.tsv").write_text("b1")

    upload_command = f"files upload {tmp_path / 'prefix_a_1.tsv'} {tmp_path / 'prefix_a_2.tsv'} {tmp_path / 'prefix_b_1.tsv'} --project {clean_project}"
    upload_result = runner.invoke(app, upload_command)
    assert upload_result.exit_code == 0

    list_command = f"files ls --project {clean_project} --prefix prefix_a"
    list_result = runner.invoke(app, list_command)
    assert list_result.exit_code == 0
    assert "prefix_a_1.tsv" in list_result.stdout
    assert "prefix_a_2.tsv" in list_result.stdout
    assert "prefix_b_1.tsv" not in list_result.stdout


def test_list_files_hides_results_files_by_default(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test that query result files are hidden by default and shown with the --include-results-files flag."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    results_file = tmp_path / f"{QUERY_RESULTS_FILE_PREFIX}1.vcf.gz"
    normal_file = tmp_path / "my_data.tsv"
    results_file.write_text("results file")
    normal_file.write_text("data file")

    upload_command = f"files upload {results_file} {normal_file} --project {clean_project}"
    upload_result = runner.invoke(app, upload_command)
    assert upload_result.exit_code == 0

    list_command = f"files ls --project {clean_project}"
    list_result = runner.invoke(app, list_command)
    assert list_result.exit_code == 0
    assert "my_data.tsv" in list_result.stdout
    assert f"{QUERY_RESULTS_FILE_PREFIX}1.vcf.gz" not in list_result.stdout

    list_command_include = f"files ls --project {clean_project} --include-results-files"
    list_result_include = runner.invoke(app, list_command_include)
    assert list_result_include.exit_code == 0
    assert "my_data.tsv" in list_result_include.stdout
    assert f"{QUERY_RESULTS_FILE_PREFIX}1.vcf.gz" in list_result_include.stdout


def test_file_info_single_version(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test the 'files info' command for a file with a single version."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    test_file = tmp_path / "info_test.tsv"
    test_file.write_text("some content")

    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0

    result = runner.invoke(app, f"files info {test_file.name} --project {clean_project}")
    assert result.exit_code == 0
    assert f"{test_file.name}" in result.stdout
    assert calculate_numb_table_rows_printed(result.stdout) == 1


def test_file_info_deleted_file(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test the 'files info' command for a file that has been deleted."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    test_file = tmp_path / "deleted_info_test.tsv"
    test_file.write_text("this file will be deleted")

    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0

    result = runner.invoke(app, f"files rm {test_file.name} --project {clean_project}")
    assert result.exit_code == 0

    result = runner.invoke(app, f"files info {test_file.name} --project {clean_project}")
    assert result.exit_code == 0
    assert "Warning: This file is marked as soft deleted" in result.stdout


def test_file_info_multiple_versions(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test 'files info' for a file with multiple versions."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    test_file = tmp_path / "multi_version_test.tsv"

    test_file.write_text("version 1")
    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0

    test_file.write_text("version 2 is different")
    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0

    test_file.write_text("version 3 is also different")
    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0

    result = runner.invoke(app, f"files info {test_file.name} --project {clean_project}")
    assert result.exit_code == 0
    assert "Warning: This file is marked as soft deleted" not in result.stdout
    assert calculate_numb_table_rows_printed(result.stdout) == 3


def test_file_info_non_existent_file(logged_in_edit_user_with_existing_config, CONSTANTS):
    """Test 'files info' for a file that does not exist."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    result = runner.invoke(app, f"files info nonexistent.tsv --project {clean_project}")
    assert result.exit_code != 0
    assert isinstance(result.exception, DivBaseAPIError)
    assert "404" in str(result.exception)
    assert "does not exist" in str(result.exception)


def test_file_info_after_reupload(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test 'files info' after a file is deleted and then re-uploaded."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    test_file = tmp_path / "reupload_test.tsv"
    test_file.write_text("initial upload")

    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0
    result = runner.invoke(app, f"files rm {test_file.name} --project {clean_project}")
    assert result.exit_code == 0

    test_file.write_text("re-uploaded with new content")
    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0

    result = runner.invoke(app, f"files info {test_file.name} --project {clean_project}")
    assert result.exit_code == 0
    assert "Warning: This file is marked as soft deleted" not in result.stdout
    assert calculate_numb_table_rows_printed(result.stdout) == 2


def test_upload_1_file(logged_in_edit_user_with_existing_config, tmp_path):
    """Test upload 1 file to the project."""
    test_file = tmp_path / "fake_test_file.tsv"
    test_file.write_text("testing, testing 1 2 3...")

    command = f"files upload {test_file}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    assert test_file.name in result.stdout


def test_upload_1_file_to_non_default_project(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    """Specify a project when uploading a file."""
    test_file = (fixtures_dir / CONSTANTS["FILES_TO_UPLOAD_DOWNLOAD"][0]).resolve()

    command = f"files upload {test_file} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    assert f"{str(test_file)}" in result.stdout


def test_upload_multiple_files_at_once(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    test_files = [(fixtures_dir / file_name).resolve() for file_name in CONSTANTS["FILES_TO_UPLOAD_DOWNLOAD"]]

    command = f"files upload {' '.join(map(str, test_files))} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    for file in test_files:
        assert f"{str(file)}" in result.stdout


def test_upload_dir_contents(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    """Test upload all files in a directory."""
    files = [x for x in fixtures_dir.glob("*") if x.is_file()]  # does not get subdirs

    command = f"files upload --upload-dir {fixtures_dir.resolve()} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    clean_stdout = result.stdout.replace("\n", "")  # newlines can cause issues in the assert below
    for file in files:
        assert str(file.resolve()) in clean_stdout


def test_reupload_same_file_fails(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    """Test upload with safe mode on (default) works the first time, but fails on subsequent attempts."""
    file_name = CONSTANTS["FILES_TO_UPLOAD_DOWNLOAD"][0]
    file_path = f"{fixtures_dir}/{file_name}"
    command = f"files upload {file_path} --project {CONSTANTS['CLEANED_PROJECT']}"

    result = runner.invoke(app, command)
    assert result.exit_code == 0

    result = runner.invoke(app, command)
    assert result.exit_code != 0
    assert isinstance(result.exception, FilesAlreadyInProjectError)


def test_reupload_of_same_file_with_safe_mode_off_works(
    logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir
):
    """Test upload with safe mode off works for reuploading the same file."""
    file_name = CONSTANTS["FILES_TO_UPLOAD_DOWNLOAD"][0]
    file_path = f"{fixtures_dir}/{file_name}"
    command = f"files upload {file_path} --project {CONSTANTS['CLEANED_PROJECT']} --disable-safe-mode"

    result = runner.invoke(app, command)
    assert result.exit_code == 0

    result = runner.invoke(app, command)
    assert result.exit_code == 0


def test_no_file_uploaded_if_some_duplicated(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    """
    Test that no files are uploaded with safe mode on (which is the default)
    if at least 1 of the files trying to be uploaded already exists in the project's bucket.
    """
    test_files = [(fixtures_dir / file_name).resolve() for file_name in CONSTANTS["FILES_TO_UPLOAD_DOWNLOAD"]]

    # upload just 1 of the files first
    command = f"files upload {test_files[0]} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    # none should be uploaded as the first one already exists
    command = f"files upload {' '.join(map(str, test_files))} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code != 0
    assert isinstance(result.exception, FilesAlreadyInProjectError)

    command = f"files ls --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert test_files[0].name in result.stdout
    for file in test_files[1:]:
        assert file.name not in result.stdout, f"File {file.name} was uploaded when it shouldn't have been."


def test_upload_nonexistent_file(logged_in_edit_user_with_existing_config, tmp_path):
    command = "files upload nonexistent_file.tsv"
    result = runner.invoke(app, command)

    assert result.exit_code != 0
    assert isinstance(result.exception, FileNotFoundError)


@pytest.mark.parametrize(
    "file_names, should_succeed",
    [
        (["data.tsv"], True),
        (["variants.vcf.gz"], True),
        (["index.csi"], True),
        (["index.tbi"], True),
        (["unsupported.txt"], False),
        (["archive.zip"], False),
        (["data.tsv", "variants.mine.vcf.gz"], True),
        (["data.tsv", "unsupported.txt", "unsupported2.txt"], False),
        (["variants.vcf.gz", "variants2.vcf.gz", "index.tbi", "index.csi"], True),
        (["unsupported.txt", "another_unsupported.zip", "supported.vcf.gz"], False),
    ],
)
def test_upload_non_supported_files_types(
    logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path, file_names, should_succeed
):
    """
    Tests that the upload command correctly handles supported and unsupported file types
    """
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    test_files = []
    for file_name in file_names:
        test_file = tmp_path / file_name
        test_file.write_text("file content")
        test_files.append(str(test_file))

    command = f"files upload {' '.join(test_files)} --project {clean_project}"
    result = runner.invoke(app, command)

    if should_succeed:
        assert result.exit_code == 0
        assert "successfully uploaded" in result.stdout.lower()
    else:
        assert result.exit_code != 0
        assert isinstance(result.exception, UnsupportedFileTypeError)


def test_upload_more_than_max_batch_size_files(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """
    Validates that the batching logic for single-part uploads works correctly when uploading
    more than MAX_S3_API_BATCH_SIZE files at once.
    """
    upload_dir = tmp_path / "many_files"
    upload_dir.mkdir()
    num_files = MAX_S3_API_BATCH_SIZE + 5

    for i in range(num_files):
        (upload_dir / f"test_file_{i}.tsv").write_text(f"content_{i}")

    command = f"files upload --upload-dir {upload_dir} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    for i in range(num_files):
        assert f"test_file_{i}.tsv" in result.stdout

    command = f"files ls --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    for i in range(num_files):
        assert f"test_file_{i}.tsv" in result.stdout


def test_safe_mode_fails_with_more_than_max_batch_size_files_if_one_exists(
    logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path
):
    """
    Tests that safe mode correctly identifies a duplicate file and raises FilesAlreadyInProjectError,
    even when the check involves more than MAX_S3_API_BATCH_SIZE files.

    The duplicated file would be in the 2nd batch of files to be uploaded as well.
    """
    upload_dir = tmp_path / "uploads_dir"
    upload_dir.mkdir()
    num_files = MAX_S3_API_BATCH_SIZE + 5

    for i in range(num_files):
        (upload_dir / f"safe_mode_test_{i}.tsv").write_text(f"content_{i}")

    duplicate_file = upload_dir / f"safe_mode_test_{MAX_S3_API_BATCH_SIZE + 4}.tsv"
    command = f"files upload {duplicate_file} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    command = f"files upload --upload-dir {upload_dir} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code != 0
    assert isinstance(result.exception, FilesAlreadyInProjectError)
    assert duplicate_file.name in str(result.exception)

    # Verify that none of the files were uploaded.
    command = f"files ls --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    for i in range(num_files - 1):
        file_name = f"safe_mode_test_{i}.tsv"
        if file_name == duplicate_file.name:
            assert f"safe_mode_test_{i}.tsv" in result.stdout
        else:
            assert f"safe_mode_test_{i}.tsv" not in result.stdout

    # Now run the upload again without safe_mode turned off, should work
    command = f"files upload --upload-dir {upload_dir} --project {CONSTANTS['CLEANED_PROJECT']} --disable-safe-mode"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    for i in range(num_files):
        assert f"safe_mode_test_{i}.tsv" in result.stdout


def test_safe_mode_fails_with_large_file_duplicate(
    logged_in_edit_user_with_existing_config, CONSTANTS, large_file_for_multipart
):
    """
    Tests that safe mode correctly identifies a duplicate large file (which has a composite ETag)
    and prevents the re-upload.

    Turning off safe mode should allow the re-upload.
    """
    large_file_path = large_file_for_multipart

    command = f"files upload {large_file_path} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    result = runner.invoke(app, command)
    assert result.exit_code != 0
    assert isinstance(result.exception, FilesAlreadyInProjectError)
    assert large_file_path.name in str(result.exception)

    # validate turning off safe mode allows re-upload
    command = f"files upload {large_file_path} --project {CONSTANTS['CLEANED_PROJECT']} --disable-safe-mode"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert large_file_path.name in result.stdout


def test_download_1_file(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    file_name = CONSTANTS["PROJECT_CONTENTS"][CONSTANTS["DEFAULT_PROJECT"]][0]
    download_dir = tmp_path / "downloads"
    download_dir.mkdir()

    command = f"files download {file_name} --download-dir {download_dir}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    assert file_name in result.stdout
    assert (download_dir / file_name).exists()


def test_download_multiple_files(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    files_in_project = CONSTANTS["PROJECT_CONTENTS"][CONSTANTS["DEFAULT_PROJECT"]]
    download_dir = tmp_path / "downloads"
    download_dir.mkdir()

    command = f"files download {' '.join(files_in_project)} --download-dir {download_dir}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    for file_name in files_in_project:
        assert file_name in result.stdout
        assert (download_dir / file_name).exists()


def test_download_from_non_default_project(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    non_default_project = CONSTANTS["NON_DEFAULT_PROJECT"]
    file_to_download = CONSTANTS["PROJECT_CONTENTS"][non_default_project][0]

    download_dir = tmp_path / "downloads"
    download_dir.mkdir()

    command = f"files download {file_to_download} --project {non_default_project} --download-dir {download_dir}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    assert file_to_download in result.stdout
    assert (download_dir / file_to_download).exists()


def test_download_using_file_list(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    files_in_project = CONSTANTS["PROJECT_CONTENTS"][CONSTANTS["DEFAULT_PROJECT"]]
    download_dir = tmp_path / "downloads"
    download_dir.mkdir()

    file_list = tmp_path / "file_list.tsv"
    with open(file_list, "w") as f:
        f.write("\n".join(files_in_project))

    command = f"files download --file-list {file_list} --download-dir {download_dir}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    for file_name in files_in_project:
        assert file_name in result.stdout
        assert (download_dir / file_name).exists()


def test_download_nonexistent_file(logged_in_edit_user_with_existing_config, tmp_path):
    download_dir = tmp_path / "downloads"
    download_dir.mkdir()

    command = f"files download nonexistent_file.tsv --download-dir {download_dir}"
    result = runner.invoke(app, command)

    assert result.exit_code != 0
    assert "ERROR: Failed to download the following files:" in result.stdout
    assert "nonexistent_file.tsv" in result.stdout


def test_download_more_than_100_files_at_once(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """
    Tests that the batching logic for downloads works correctly when downloading
    more than MAX_S3_API_BATCH_SIZE (100) files at once.
    """
    upload_dir = tmp_path / "many_files_for_download"
    upload_dir.mkdir()
    num_files = 105

    for i in range(num_files):
        (upload_dir / f"download_test_{i}.tsv").write_text(f"content_{i}")
    command = f"files upload --upload-dir {upload_dir} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    download_dir = tmp_path / "downloads_dir"
    download_dir.mkdir()
    file_names_to_download = [f"download_test_{i}.tsv" for i in range(num_files)]

    command = f"files download {' '.join(file_names_to_download)} --download-dir {download_dir} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    for i in range(num_files):
        file_name = f"download_test_{i}.tsv"
        assert file_name in result.stdout
        assert (download_dir / file_name).exists()
        assert (download_dir / file_name).read_text() == f"content_{i}"


def test_download_specific_file_versions(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """
    Tests that the download command can fetch a specific older version of one file
    and the latest version of another file in the same command.
    """
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    download_dir = tmp_path / "download_version_test"
    download_dir.mkdir()

    versioned_file = tmp_path / "versioned_file.tsv"
    versioned_file.write_text("content v1")
    result = runner.invoke(app, f"files upload {versioned_file} --project {clean_project}")
    assert result.exit_code == 0

    versioned_file.write_text("content latest v2")
    result = runner.invoke(app, f"files upload {versioned_file} --project {clean_project}")
    assert result.exit_code == 0

    latest_file = tmp_path / "latest_file.tsv"
    latest_file.write_text("content latest v1")
    result = runner.invoke(app, f"files upload {latest_file} --project {clean_project}")
    assert result.exit_code == 0

    latest_file.write_text("content latest v2")
    result = runner.invoke(app, f"files upload {latest_file} --project {clean_project}")
    assert result.exit_code == 0

    # Get the version ID for versioned_file
    info_command = f"files info {versioned_file.name} --project {clean_project} --tsv"
    info_result = runner.invoke(app, info_command)
    assert info_result.exit_code == 0
    tsv_reader = csv.reader(StringIO(info_result.stdout), delimiter="\t")
    rows = list(tsv_reader)
    # The first data row is the latest version (v2), the second is the older one (v1)
    version_id_v1 = rows[2][3]

    download_command = (
        f"files download {versioned_file.name}:{version_id_v1} {latest_file.name} "
        f"--project {clean_project} --download-dir {download_dir}"
    )
    download_result = runner.invoke(app, download_command)
    assert download_result.exit_code == 0
    assert "Successfully downloaded" in download_result.stdout

    downloaded_versioned_file = download_dir / versioned_file.name
    assert downloaded_versioned_file.exists()
    assert downloaded_versioned_file.read_text() == "content v1"

    downloaded_latest_file = download_dir / latest_file.name
    assert downloaded_latest_file.exists()
    assert downloaded_latest_file.read_text() == "content latest v2"


def test_download_at_a_project_version(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path, fixtures_dir):
    """Test downloading at specified project versions."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]

    download_dir = tmp_path / "download_v1"
    download_dir.mkdir()

    file_name = "test_file.tsv"
    file_path = tmp_path / file_name
    v1_content = "This is version 1.0.0 content"
    v2_content = "This is version 2.0.0 content - UPDATED"

    # Create file, upload v1 contents and create project version v1.0.0
    with open(file_path, "w") as f:
        f.write(v1_content)

    command = f"files upload {file_path} --project {clean_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    command = f"version add v1.0.0 --project {clean_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    # Create file, upload v2 contents and create project version v2.0.0
    with open(file_path, "w") as f:
        f.write(v2_content)

    command = f"files upload {file_path} --project {clean_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    command = f"version add v2.0.0 --project {clean_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    # Download + assert contents at v1.0.0
    command = (
        f"files download {file_name} --project-version v1.0.0 --project {clean_project} --download-dir {download_dir}"
    )
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert (download_dir / file_name).exists()

    with open(download_dir / file_name) as f:
        downloaded_content = f.read()
    assert downloaded_content == v1_content

    # Download + assert contents at v2.0.0
    command = (
        f"files download {file_name} --project-version v2.0.0 --project {clean_project} --download-dir {download_dir}"
    )
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert (download_dir / file_name).exists()

    with open(download_dir / file_name) as f:
        downloaded_content = f.read()
    assert downloaded_content == v2_content

    # Download without specifying project version works like "latest"
    command = f"files download {file_name} --project {clean_project} --download-dir {download_dir}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert (download_dir / file_name).exists()

    with open(download_dir / file_name) as f:
        downloaded_content = f.read()
    assert downloaded_content == v2_content


def test_upload_and_download_large_file_triggers_multipart(
    logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path, large_file_for_multipart
):
    """
    Tests that a file large enough to trigger the multipart protocol can be successfully
    uploaded and then downloaded, verifying its checksum.
    """
    large_file_path = large_file_for_multipart
    expected_checksum = calculate_composite_md5_s3_etag(file_path=large_file_path)

    command = f"files upload {large_file_path} --project {CONSTANTS['CLEANED_PROJECT']}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert large_file_path.name in result.stdout

    download_dir = tmp_path / "large_file_downloads"
    download_dir.mkdir()
    command = (
        f"files download {large_file_path.name} --project {CONSTANTS['CLEANED_PROJECT']} --download-dir {download_dir}"
    )
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    # manually verify checksum of downloaded file (should have also been verified during download)
    downloaded_file_path = download_dir / large_file_path.name
    assert downloaded_file_path.exists()
    downloaded_checksum = calculate_composite_md5_s3_etag(file_path=downloaded_file_path)
    assert downloaded_checksum == expected_checksum


def test_stream_file(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    """Test streaming a simple text file."""
    query_project = CONSTANTS["QUERY_PROJECT"]
    file_to_stream = "sample_metadata.tsv"
    file_path = fixtures_dir / file_to_stream
    expected_content = file_path.read_text()

    result = runner.invoke(app, f"files stream {file_to_stream} --project {query_project}")
    assert result.exit_code == 0
    assert result.stdout == expected_content


def test_stream_gzipped_file(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    """Test streaming a gzipped file."""
    query_project = CONSTANTS["QUERY_PROJECT"]
    file_to_stream = "HOM_20ind_17SNPs_first_10_samples.vcf.gz"
    file_path = fixtures_dir / file_to_stream
    expected_content = file_path.read_bytes()

    result = runner.invoke(app, f"files stream {file_to_stream} --project {query_project}")
    assert result.exit_code == 0
    assert result.stdout_bytes == expected_content


def test_remove_with_dry_run(logged_in_edit_user_with_existing_config, CONSTANTS):
    file_name = CONSTANTS["PROJECT_CONTENTS"][CONSTANTS["DEFAULT_PROJECT"]][0]

    command = f"files rm {file_name} --dry-run"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    assert f"{file_name}" in result.stdout

    command = "files ls"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert file_name in result.stdout


def test_remove_file(logged_in_edit_user_with_existing_config, CONSTANTS, fixtures_dir):
    """Test removing a file from the project's bucket, using a clean project to avoid side effects in other tests."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]

    file_name = CONSTANTS["FILES_TO_UPLOAD_DOWNLOAD"][0]
    file_path = f"{fixtures_dir}/{file_name}"

    command = f"files upload {file_path} --project {clean_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0

    command = f"files ls --project {clean_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert file_name in result.stdout

    command = f"files rm {file_name} --project {clean_project}"
    result = runner.invoke(app, command)

    assert result.exit_code == 0
    assert f"{file_name}" in result.stdout

    command = f"files ls --project {clean_project}"
    result = runner.invoke(app, command)
    assert result.exit_code == 0
    assert file_name not in result.stdout


def test_restore_deleted_file(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test restoring a file that was soft-deleted."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    test_file = tmp_path / "file_to_restore.tsv"
    test_file.write_text("This file will be deleted and then restored.")

    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0
    result = runner.invoke(app, f"files rm {test_file.name} --project {clean_project}")
    assert result.exit_code == 0

    result = runner.invoke(app, f"files download {test_file.name} --project {clean_project} --download-dir {tmp_path}")
    assert result.exit_code != 0
    assert "404" in result.stdout
    assert test_file.name in result.stdout

    result = runner.invoke(app, f"files restore {test_file.name} --project {clean_project}")
    assert result.exit_code == 0
    assert "restored files:" in result.stdout.lower()
    assert test_file.name in result.stdout

    result = runner.invoke(app, f"files download {test_file.name} --project {clean_project} --download-dir {tmp_path}")
    assert result.exit_code == 0
    assert "404" not in result.stdout
    assert test_file.name in result.stdout
    assert "successfully downloaded" in result.stdout.lower()


def test_restore_already_live_file(logged_in_edit_user_with_existing_config, CONSTANTS, tmp_path):
    """Test that attempting to restore a multiple times does no harm and operation is idempotent."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    test_file = tmp_path / "already_alive_file.tsv"
    test_file.write_text("This file was never deleted.")

    result = runner.invoke(app, f"files upload {test_file} --project {clean_project}")
    assert result.exit_code == 0

    for _ in range(3):
        result = runner.invoke(app, f"files restore {test_file.name} --project {clean_project}")
        assert result.exit_code == 0
        assert "restored files:" in result.stdout.lower()
        assert test_file.name in result.stdout

    result = runner.invoke(app, f"files download {test_file.name} --project {clean_project} --download-dir {tmp_path}")
    assert result.exit_code == 0
    assert "404" not in result.stdout
    assert test_file.name in result.stdout
    assert "successfully downloaded" in result.stdout.lower()


def test_restore_non_existent_file(logged_in_edit_user_with_existing_config, CONSTANTS):
    """Test that attempting to restore a non-existent file reports it as 'not found'."""
    clean_project = CONSTANTS["CLEANED_PROJECT"]
    non_existent_file = "i_do_not_exist.tsv"

    result = runner.invoke(app, f"files restore {non_existent_file} --project {clean_project}")
    assert result.exit_code == 0
    assert "warning: some files could not be restored" in result.stdout.lower()
    assert non_existent_file in result.stdout
